% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fmglm.R
\name{fmglm}
\alias{fmglm}
\title{Finite Mixture of Generalized Linear Models (fmglm) Object}
\value{
Returns R6 object of class fmglm.
}
\description{
A finite mixture of generalized linear model (GLM)
}
\section{Introduction of \code{fmglm} class}{

The \code{fmglm} class is designed to fit the finite mixture of generalized linear
models including the multinomial regression models.
It contains three major methods:
\itemize{
\item \verb{$new()} creates a \code{fmglm} object given \code{data} and \code{formula}
\item \verb{$fit()} fits the \code{fmglm} model. The algorithm used to fit and
the starting method can also be specified in the method. In addition,
this method returns a result list containing coefficients, loglikelihood value,
and information criterion such as AIC and BIC.
\item \verb{$summarize()} generates the table output of the results including
the standard errors and p-values.
}
}

\section{The Normal Likelihood Function Vs. The Complete-Data Likelihood Function}{

The Finite Mixture Model (FMM) with \eqn{K} components can be written in the following form:
\deqn{f(y|x, \phi) = \sum_{k=1}^K{\pi_k f_k(y|x, \theta_k)}}

Based on the above equation, the log-likelihood function is:
\deqn{\log(L) = \sum_{i=1}^N \log{f(y_i|x_i, \phi)} = \sum_{i=1}^N \log {\sum_{k=1}^K{\pi_k f_k(y_i|x_i, \theta_k)}}}

The log-likelihood function can be maximized separately for each component in the M-step,
given the posterior probabilities as weights:
\deqn{\max_{\theta_k} \sum_{i=1}^N \hat{p_{ik}} \log f_k(y_i|x_i, \theta_k)}

where \eqn{p_{ik}} is the posterior probabilty estimated in the E-step.
This approach is used in other packages, such as \CRANpkg{flexmix}.

Similar to \CRANpkg{flexmix}, we use \code{glm.fit()} and \code{lm.wfit()}, to fit the log-likelihood function by components.
To use it, set \code{optim_method} to either \code{glm} or \code{lm} and \code{use_llc} to \code{FALSE}.

Alternative, FMM can be viewed as a model with incomplete data where the variable to determine individual's class is missing.
The imputed variable \eqn{z_ik = 1} or {0} captures the classification of each sample.
Therefore, the complete-data log-likelihood is:
\deqn{\log L_c = \sum_{k=1}^K \sum_{i=1}^N z_ik \{ \log{\pi} + \log{f_k(y_i|x_i, \theta_k)} \} }

In this package, we use \code{optim} with the BFGS algorithm to maximize the complete-data log-likelihood.
And this method is the default method to fit FMM. As this method involves a mixed log-likelihood function,
we use Rcpp to speed up the computation.
}

\section{Alternative Algorithm to EM-algorithm}{


In addition to the normal EM-algorithm, \verb{$fit()} can also choose two extended algorithms of the EM-algorithm.
\itemize{
\item The Classification EM (\code{cem}) assigns each sample to a component based on the maximum value of its posterior probabilities.
\item The Stocastic EM (\code{sem}) randomly assigns each sample to a component based on its posterior probabilities.
}
}

\section{Use \code{fmglm} to Fit Finite Mixture of Generalized Linear Models}{

The main practice of \code{fmglm} is to fit finite mixture of generalized linear models
such as linear regressions with Gaussian distributions or Poisson distribution.
To fit a linear regression with Gaussian distribution, run the code similar to the following:\preformatted{model1 <- fmglm$new(formula1, data, family="gaussian", latent=2)
result <- model1$fit()
output <- model1$summarize()
}

Benefit from the chain feature of R6, the code can be written in one line like the following:\preformatted{result <-fmglm$new(formula1, data, family="gaussian", latent=2)$fit()$summarize()
}
}

\section{Use \code{fmglm} to Fit Finite Mixture of Multinomial Regression Models}{


\code{fmglm} can fit finite mixture of multinomial regression models as well.
In general the code is similar to fitting the mixture of generalized linear models.\preformatted{model_mn <- fmglm$new(formula, data, family="multinom",
                      latent=2, method="em")
}

The difference is that one should prepare the dependent variable as a \code{factor} variable.
In addition, the parameter \code{mn_base} is available in the constructor for identifying
the base group of the dependent variable. The default value is \code{1}.
}

\author{
Dongjie Wu
}
\section{Super class}{
\code{\link[fmmr6:fmmr6]{fmmr6::fmmr6}} -> \code{fmglm}
}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{data_model}}{(\code{DataModel()}) \cr
The DataModel Object that stores the data using in the fmmr6.}

\item{\code{family}}{(\code{character(1)|character()}) \cr
The distribution family which can be either a string like "gaussian"
or a vector like \code{c("gaussian", "gaussian")}.}

\item{\code{latent}}{(\code{integer(1)}) \cr
The number of latent classes.}

\item{\code{method}}{(\code{character(1)}) \cr
The estimation method to fit the fmglm.}

\item{\code{start}}{(\code{matrix()}) \cr
The starting values for the fmglm.}

\item{\code{constraint}}{(\code{matrix()}) \cr
The constraint matrix.}

\item{\code{concomitant}}{(\code{formula(1)})\cr
The formula to model the concomitant model.
The default value is NULL.}

\item{\code{optim_method}}{(\code{character(1)}) \cr
The optimization method to use to fit the model.}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-new}{\code{fmglm$new()}}
\item \href{#method-fit}{\code{fmglm$fit()}}
\item \href{#method-summarize}{\code{fmglm$summarize()}}
\item \href{#method-clone}{\code{fmglm$clone()}}
}
}
\if{html}{
\out{<details open ><summary>Inherited methods</summary>}
\itemize{
\item \out{<span class="pkg-link" data-pkg="fmmr6" data-topic="fmmr6" data-id="predict">}\href{../../fmmr6/html/fmmr6.html#method-predict}{\code{fmmr6::fmmr6$predict()}}\out{</span>}
}
\out{</details>}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-new"></a>}}
\if{latex}{\out{\hypertarget{method-new}{}}}
\subsection{Method \code{new()}}{
Create a new instance of this \link{R6} \link[R6:R6Class]{R6::R6Class} class.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{fmglm$new(
  formula,
  data,
  data_str = "default",
  data_var = NULL,
  family = "gaussian",
  latent = 2,
  method = "em",
  start = NULL,
  optim_method = "base",
  concomitant = NULL,
  use_llc = TRUE,
  mn_base = 1,
  constraint = matrix(1)
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{formula}}{(\code{formula(1)}) \cr
The formula/expression of the model to fit in the fmglm.}

\item{\code{data}}{(\code{data.frame()}) \cr
The Data used in the fmglm.}

\item{\code{family}}{(\code{character(1)|character()}) \cr
The distribution family which can be either a string like "gaussian".
or a vector like \code{c("gaussian", "gaussian")}.}

\item{\code{latent}}{(\code{integer(1)}) \cr
The number of latent classes.}

\item{\code{method}}{(\code{character(1)}) \cr
The estimation method to fit the fmglm.}

\item{\code{start}}{(\code{matrix()}) \cr
The starting values for the fmglm.}

\item{\code{optim_method}}{(\code{character(1)}) \cr
The optimization method to use to fit the model.
The default is \code{base}.}

\item{\code{concomitant}}{(\code{formula(1)}) \cr
The formula for the concomitant model. E.g. \code{~ z1 + z2 + z3}.}

\item{\code{use_llc}}{(\code{boolean(1)}) \cr
Whether to use the complete log-likelihood or the normal log-likelihood.
The default is \code{TRUE}.}

\item{\code{mn_base}}{(\code{integer(1)}) \cr
Determine which column of the multinomial variable is set to be the base group.}

\item{\code{constraint}}{(\code{matrix()}) \cr
The constraint matrix.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
Return a R6 object of class fmglm
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-fit"></a>}}
\if{latex}{\out{\hypertarget{method-fit}{}}}
\subsection{Method \code{fit()}}{
Fit the fmglm model
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{fmglm$fit(algo = "em", max_iter = 500, start = "random", rep = 1, verbose = F)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{algo}}{(\code{character(1)}) \cr
The algorithm used in fitting the fmglm model.
The default algorithm is \code{em} standing for the normal EM algorithm.
One can choose from \code{c("em", "cem", "sem")}.
\code{cem} is the classification EM algorithm.
\code{sem} is the stochastic EM algorithm.}

\item{\code{max_iter}}{(\code{integer(1)}) \cr
Specify the maximum number of iterations for the E-step-M-step loop.
The default number is 500.}

\item{\code{start}}{(\code{character(1)}) \cr
Specify the starting method of the EM algorithm.
Can either start from \code{kmeans} or \code{random}.
\code{kmeans} use the K-mean methods to put samples into latent classes.
\code{random} randomly assigns samples into latent classes.
The default method is \code{kmeans}.}

\item{\code{rep}}{(\code{integer(1)}) \cr
Specify the number of reps EM-algorithm runs.
This parameter is designed for preventing the local maximum.
Each rep, the EM_algorithm generates a start.
It is only useful when \code{start} is \code{random}.
After all reps, the algorithm will pick the rep with maximum log likelihood.
The default value is 1}

\item{\code{verbose}}{(\code{boolean(1)}) \cr
Print the converging log-likelihood for all steps.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-summarize"></a>}}
\if{latex}{\out{\hypertarget{method-summarize}{}}}
\subsection{Method \code{summarize()}}{
Generate a summary for the result.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{fmglm$summarize(digits = 3)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{digits}}{(\code{integer(1)}) \cr
Determine how many digits presented in the output.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-clone"></a>}}
\if{latex}{\out{\hypertarget{method-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{fmglm$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
